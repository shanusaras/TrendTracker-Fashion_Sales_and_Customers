# -*- coding: utf-8 -*-
"""Online_Fashion_Data_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uypfFLzIfgf6tWFmLpsKPQeubL6Zb_Qx

# PERSONAL DATA

### **Saraswathi R**

Portfolio:
* [LinkedIn](https://www.linkedin.com/in/saraswathi-rajendran-29b962205/?originalSubdomain=in)
* [Github](https://github.com/shanusaras)

# DESCRIPTION

- **Online Fashion Analysis** is a data analysis project that utilizes sales data from a fashion company called **Dicoding Collection (DiCo)**. **DiCo** is an online company that produces and sells various fashion items. Recognizing the importance of data in business development, DiCo maintains comprehensive records of all sales history, product information, and customer data in their database.

- The **objective** of this project is to evaluate the company's sales performance, identify the best and worst-selling fashion products, and gain deeper insights into customer demographics. By better understanding their customers, DiCo can develop more effective marketing campaigns.

- The database consists of four main tables: **customers**, **orders**, **products**, and **sales**. [Legend](https://github.com/shanusaras/TrendTracker-Fashion_Sales_and_Customers/blob/main/dataset/Legend.txt)

- Dataset: [DicodingCollection](https://github.com/dicodingacademy/dicoding_dataset/tree/main/DicodingCollection)

Key business questions to be answered through this analysis:

1. How has the company's sales and revenue performed in recent months?
2. Which products are the best and worst sellers?
3. What are the demographic characteristics of the company's customer base?
4. When was the last time each customer made a transaction?
5. How frequently do customers make purchases in recent months?
6. How much money do customers spend on average in recent months?

# DATA WRANGLING

## Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

pd.set_option('display.max_columns', None)
plt.rc('axes', grid=True)

# %matplotlib inline

"""## Gathering Data

### Customers
"""

customers_df = pd.read_csv('https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/DicodingCollection/customers.csv')
customers_df.head()

"""### Orders"""

orders_df = pd.read_csv('https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/DicodingCollection/orders.csv')
orders_df.head()

"""### Product"""

product_df = pd.read_csv('https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/DicodingCollection/products.csv')
product_df.head()

"""### Sales"""

sales_df = pd.read_csv('https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/DicodingCollection/sales.csv')
sales_df.head()

"""## Assessing Data

### Customers
"""

customers_df.info()

customers_df.isnull().sum()

"""- The output above shows that there are 18 missing values in the gender column."""

print('Number of duplicates in customer data: ', customers_df.duplicated().sum())

customers_df.describe()

"""- The output shows an inaccurate value in the maximum value of the age column: 700.00. This appears to be an outlier or data entry error, as 700 years is not a realistic age for a customer.

### Orders
"""

orders_df.info()

"""1. **Missing Values**:
   - No missing values found in the `orders_df` dataset

2. **Data Type Issues**:
   - The `order_date` and `delivery_date` columns are currently of type **object**
   - These should be converted to **datetime** format for proper date manipulation and analysis

3. **Data Validation**:
   - Consider checking for illogical date ranges (e.g., delivery dates before order dates)
   - Verify that all dates fall within the expected business operation period
"""

print('Number of duplicates in order data: ', orders_df.duplicated().sum())

orders_df.describe()

"""No unusual values were found in the `orders_df` output above

### Product
"""

product_df.info()

print('Number of duplicates in product data: ', product_df.duplicated().sum())

product_df.describe()

"""### Sales"""

sales_df.info()

sales_df.isnull().sum()

"""- The output above shows there are 19 missing values in the `total_price` column."""

print('Number of duplicates in sale data: ', sales_df.duplicated().sum())

sales_df.describe()

"""The results above indicate there are no unusual data points in the dataset.

## Cleaning Data

### Customers

#### Drop duplicate data
"""

customers_df.drop_duplicates(inplace=True)

print('Number of duplicates in customer data: ', customers_df.duplicated().sum())

"""#### Handling missing values"""

# View rows containing missing value
customers_df[customers_df.gender.isnull()]

"""### Data Imputation Strategy:

Even though these rows contain missing values, they still hold valuable information that can be extracted. Therefore, in this case, we will use **imputation methods** to fill in the missing values.
"""

customers_df.gender.value_counts()

customers_df.gender.fillna(value='Prefer not to say', inplace=True)

customers_df.isnull().sum()

customers_df.gender.value_counts()

"""#### Handling inaccurate values"""

customers_df[customers_df.age == customers_df.age.max()]

"""The analysis suggests that the inaccurate values are likely due to **human error**, resulting in excessive zeros. To address this data quality issue, these values will be replaced with **70**, which is a more reasonable and realistic value for the given context.

**Rationale**:
- 70 is a plausible value that falls within expected ranges
- This approach preserves the data points while correcting obvious errors
- It's more statistically sound than removing the records entirely
"""

customers_df.age.replace(customers_df.age.max(), 70, inplace=True)

customers_df[customers_df.age == customers_df.age.max()]

"""Turns out there are still other invalid values in the age column.

The likely cause of this error is the same as before - *human error* resulting in excessive zeros. To address this, we will replace these values with **50**.
"""

customers_df.age.replace(customers_df.age.max(), 50, inplace=True)

customers_df[customers_df.age == customers_df.age.max()]

customers_df.describe()

"""From these results, it's clear that the `age` column now has a reasonable maximum value. Additionally, the mean and standard deviation have changed after addressing the inaccurate values.

### Orders

- In the previous data assessment process, it was found that there are errors in the data types for the `order_date` and `delivery_date` columns.
- Both of these columns will be changed to the `datetime` data type.
"""

datetime_columns = ['order_date', 'delivery_date']

for column in datetime_columns:
    orders_df[column] = pd.to_datetime(orders_df[column])

orders_df.info()

"""### Product

- In the previous data assessment, it was found that there are 6 duplicate entries in `product_df`.
- These duplicate entries will be dropped.
"""

product_df.drop_duplicates(inplace=True)

print('Number of duplicates in product data: ', product_df.duplicated().sum())

"""### Sales

From the previous data assessment, it can be concluded that there are 19 missing values in the `total_price` column.
"""

sales_df[sales_df.total_price.isnull()]

sales_df.head(3)

"""From the data display, we can observe that the `total_price` value is obtained by multiplying `price_per_unit` by `quantity`. We can use this pattern to handle the missing values in the `total_price` column."""

sales_df['total_price'] = sales_df['price_per_unit'] * sales_df['quantity']

sales_df.isnull().sum()

sales_df[sales_df['sales_id'] == 121]

"""# EXPLORATORY DATA ANALYSIS

## Customers
"""

customers_df.describe(include='all')

customers_df.groupby(by='gender').agg({
    'customer_id': 'nunique',
    'age': ['max', 'min', 'mean', 'std']
})

customers_df.groupby(by='city').customer_id.nunique().sort_values(ascending=False)

customers_df.groupby(by='state').customer_id.nunique().sort_values(ascending=False)

"""- It appears that customer distribution is quite even across each city and state.
- The cities with the highest number of customers are East Aidan, East Sophia, and New Ava, each with three customers.
- Additionally, the state with the highest number of customers is South Australia.

## Orders
"""

orders_df.head(2)

"""Create a new column to store the delivery time for each order."""

delivery_time = orders_df['delivery_date'] - orders_df['order_date']
delivery_time

delivery_time = delivery_time.apply(lambda x: x.total_seconds())
delivery_time

# Next, convert to days (divide by 86400)
orders_df['delivery_time'] = round(delivery_time/86_400)

orders_df.head(2)

orders_df.describe(include='all')

"""- From the output, it can be concluded that the average delivery time is **14 days**, with a maximum of **27 days** and a minimum of **1 day**.

## Orders and Customers

- In the `orders_df` data, there is a column containing information about `customer_id` of customers who have placed orders. This information can be used to identify customers who have **not** placed any orders.
- To do this, we can create a new column called `status` in the `customers_df` data.
- This `status` column will have the value `"Active"` for customers who have placed at least one order.
- Conversely, the `status` column will have the value `"Non Active"` for customers who have never placed any orders.
"""

customer_id_in_orders_df = orders_df.customer_id.tolist()
customers_df['status'] = customers_df['customer_id'].apply(
    lambda x: 'Active' if x in customer_id_in_orders_df else 'Non Active'
)
customers_df.sample(5)

customers_df.groupby(by='status').customer_id.count()

"""Based on the pivot table above, it appears that there are a number of customers who have never made any transactions. This is bad news as nearly **30%** of all customers have never placed an order before.

### Merge

- Perform a merge process to combine information from both datasets.
- This will allow us to analyze the relationship between the two datasets and gain deeper insights.
"""

orders_customers_df = pd.merge(
    left=orders_df,
    right=customers_df,
    how='left',
    left_on='customer_id',
    right_on='customer_id'
)
orders_customers_df.head()

"""### Number of orders by city"""

orders_customers_df.groupby(by='city').order_id.nunique().sort_values(ascending=False).reset_index().head(10)

"""- Jordanside and New Ava are the two cities with the highest number of orders."""

orders_customers_df[orders_customers_df['city'] == 'Jordanside']

"""### Number of orders by state"""

orders_customers_df.groupby(by='state').order_id.nunique().sort_values(ascending=False).reset_index()

"""- South Australia is the state with the highest number of orders.

### Number of orders by gender
"""

orders_customers_df.groupby(by='gender').order_id.nunique().sort_values(ascending=False).reset_index()

"""- Based on the output above, most orders were made by customers who 'prefer not to say' their gender.

### Number of orders by age group

- Explore the number of orders by age group.
- To do this, we need to define a new column called `age_group`.
- This column will help us categorize customers into three groups: ***youth***, ***adults***, and ***seniors***.
"""

orders_customers_df['age_group'] = orders_customers_df.age.apply(
    lambda x: 'Youth' if x <= 24 else (
        'Seniors' if x > 64 else 'Adults'
    )
)

orders_customers_df.groupby(by='age_group').order_id.nunique().sort_values(ascending=False).reset_index()

"""- The highest number of orders come from the `Adults` age group.

## Product and Sales
"""

product_df.describe(include='all')

"""- The price of items sold ranges from **90** to **119** dollars."""

sales_df.describe(include='all')

"""- In each transaction, customers purchase a maximum of three items (`quantity`) of a single product type, with a total price of **357** dollars."""

product_df.sort_values(by='price', ascending=False)

"""- From the output above, the most expensive product is a jacket item named 'Parka', while the most affordable one is named 'Bomber'."""

product_df.groupby(by='product_type').agg({
    'product_id': 'nunique',
    'quantity': 'sum',
    'price': ['min', 'max']
})

product_df.groupby(by='product_name').agg({
    'product_id': 'nunique',
    'quantity': 'sum',
    'price': ['min', 'max']
})

"""### Merge

- Merge the `product_df` and `sales_df` tables to identify the best-selling products.
- This will help us analyze sales performance and identify top-performing items.
"""

sales_product_df = pd.merge(
    left=sales_df,
    right=product_df,
    how='left',
    left_on='product_id',
    right_on='product_id'
)
sales_product_df.head()

"""The result of the merge process above shows a discrepancy between the values of `price_per_unit` and `price`. This difference may be caused by **discounts**, **operational costs**, and **other applicable charges**."""

sales_product_df.groupby(by='product_type').agg({
    'sales_id': 'nunique',
    'quantity_x': 'sum',
    'total_price': 'sum'
})

"""- `Trousers` is the best-selling product type with `sales_id` 1683 and `quantity_x` 3360.
- However, in terms of **revenue** (`total_price`) generated, `Jacket` is the product type that contributes the most to the **company's revenue**.
"""

sales_product_df.groupby(by='product_name').agg({
    'sales_id': 'nunique',
    'quantity_x': 'sum',
    'total_price': 'sum'
}).sort_values(by='total_price', ascending=False)

"""- The `Denim` product is the best-selling item and also contributes the most **revenue** to the company.

## Explore all_df Data

- The purpose of this step is to analyze purchasing patterns based on customer **demographics**.
- To achieve this, we will create a new DataFrame called `all_df`.
- This DataFrame will be used to merge and store all information from the four available tables.
"""

all_df = pd.merge(
    left=sales_product_df,
    right=orders_customers_df,
    how='left',
    left_on='order_id',
    right_on='order_id'
)
all_df.head()

all_df.info()

all_df.groupby(by=['state', 'product_type']).agg({
    'quantity_x': 'sum',
    'total_price': 'sum'
})

"""- The pivot table above provides an overview of user preferences for `product_type` by `state`.
- The `Jacket` product type has the highest sales in the states of **New South Wales**, **Queensland**, and **Tasmania**.
"""

all_df.groupby(by=['gender', 'product_type']).agg({
    'quantity_x': 'sum',
    'total_price': 'sum'
})

"""- The highest total sales were in the `Prefer not to say` category, amounting to **255,085** dollars for the **Jacket** `product_type`.

"""

all_df.groupby(by=['age_group', 'product_type']).agg({
    'quantity_x': 'sum',
    'total_price': 'sum'
})

"""- The highest total sales came from the `Adults` age group, amounting to **245,055** dollars.

# DATA VISUALIZATION

## 1st Question

How is the Sales Performance and Company Revenue in Recent Months?

1. The objective is to resample the `order_date` data into **monthly** intervals.
2. Additionally, we will perform aggregation on this data.
3. This aggregation aims to obtain information about the `number of orders` and `total revenue` for **each month**.
"""

monthly_orders_df = all_df.resample(rule='M', on='order_date').agg({
    'order_id': 'nunique',
    'total_price': 'sum'
})
monthly_orders_df

monthly_orders_df.index = monthly_orders_df.index.strftime('%B')
monthly_orders_df = monthly_orders_df.reset_index()
monthly_orders_df

monthly_orders_df.rename(columns={
    'order_id': 'order_count',
    'total_price': 'revenue'
}, inplace=True)

monthly_orders_df.head()

sns.set_style('darkgrid')
plt.figure(figsize=(10, 5))
plt.plot(
    monthly_orders_df['order_date'],
    monthly_orders_df['order_count'],
    marker='o',
    linewidth=2,
    color='#72BCD4'
)
plt.title('Number of Orders per Month (2021)', fontsize=16)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

for i in range(len(monthly_orders_df)):
    plt.text(
        monthly_orders_df['order_date'][i],
        monthly_orders_df['order_count'][i] + 0.5,
        monthly_orders_df['order_count'][i],
        ha='left',
        va='bottom',
        fontsize=8
    )

"""- Based on the visualization above, it can be observed that the month with the **highest** number of orders is **March**.
- Additionally, there was a significant **decrease** in the number of orders in **February, April, May, and October**.
"""

plt.figure(figsize=(10, 5))
plt.plot(
    monthly_orders_df['order_date'],
    monthly_orders_df['revenue'],
    marker='o',
    linewidth=2,
    color='#72BCD4'
)
plt.title('Total Revenue per Month (2021)', fontsize=16)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

for i in range(len(monthly_orders_df)):
    plt.text(
        monthly_orders_df['order_date'][i],
        monthly_orders_df['revenue'][i] + 500,
        monthly_orders_df['revenue'][i],
        ha='left',
        va='bottom',
        fontsize=8

    )

"""- There was a significant **decrease** in the number of orders in **February, April, May, and October**.
- This decline has impacted the company's revenue.
- To understand the reasons behind this decrease, further analysis is needed, considering factors such as competition, marketing campaigns, and other relevant aspects.

## 2nd Question

- Which Products Are the Best and Worst Sellers?

- The goal of this question is to identify the **best-selling** and **least-selling** products.
"""

sum_order_items_df = all_df.groupby(by='product_name').quantity_x.sum().sort_values(ascending=False).reset_index()
sum_order_items_df.head(len(sum_order_items_df))

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(24, 6))

colors = ['#72BCD4', '#D3D3D3', '#D3D3D3', '#D3D3D3', '#D3D3D3']

# Plot pertama
sns.barplot(
    x='quantity_x',
    y='product_name',
    data=sum_order_items_df.head(5),
    palette=colors,
    ax=ax[0]
)
ax[0].set_ylabel(None)
ax[0].set_xlabel(None)
ax[0].set_title('Best Performing Product', loc='center', fontsize=15)
ax[0].tick_params(axis='y', labelsize=12)

for i in range(len(sum_order_items_df.head(5))):
    ax[0].text(
        sum_order_items_df['quantity_x'].iloc[i] + 4,
        i,
        sum_order_items_df['quantity_x'].iloc[i],
        va='center',
        fontsize=12
    )

# Plot kedua
asc_sum_order = sum_order_items_df.sort_values(
    by='quantity_x', ascending=True
).head(5)

sns.barplot(
    x='quantity_x',
    y='product_name',
    data=asc_sum_order,
    palette=colors,
    ax=ax[1]
)
ax[1].set_ylabel(None)
ax[1].set_xlabel(None)
ax[1].invert_xaxis()
ax[1].yaxis.set_label_position('right')
ax[1].yaxis.tick_right()
ax[1].set_title('Worst Performing Product', loc='center', fontsize=15)
ax[1].tick_params(axis='y', labelsize=12)

for i, value in enumerate(asc_sum_order['quantity_x']):
    ax[1].text(
        value + 11,
        i,
        value,
        va='center',
        fontsize=12
    )

plt.suptitle('Best and Worst Performing Product by Number of Sales', fontsize=20)

"""- Based on the image above, it can be seen that **Denim** products have the **highest** sales.
- On the other hand, **Mandarin Collar** products have the **lowest** sales.

## 3rd Question

- What is the Demographic Profile of Our Customers?

- The purpose of this question is to gather and store information about the number of customers across various demographic segments, such as gender, state, and other relevant categories.

### By gender
"""

bygender_df = all_df.groupby(by='gender').customer_id.nunique().reset_index()
bygender_df.rename(columns={
    'customer_id': 'customer_count'
}, inplace=True)

bygender_df

desc_bygender_df = bygender_df.sort_values(by='customer_count', ascending=False)

plt.figure(figsize=(10, 5))

sns.barplot(
    data=desc_bygender_df,
    y='customer_count',
    x='gender',
    palette=colors
)
plt.title('Number of Customer by Gender', loc='center', fontsize=15)
plt.ylabel(None)
plt.xlabel(None)
plt.tick_params(axis='x', labelsize=12)

for i, value in enumerate(desc_bygender_df['customer_count']):
    plt.text(
        i,
        value + 5,
        value,
        ha='center'
    )

"""- From the plot above, it can be seen that the majority of customers have not disclosed their gender information.

### By age
"""

byage_df = all_df.groupby(by='age_group').customer_id.nunique().reset_index()
byage_df.rename(columns={
    'customer_id': 'customer_count'
}, inplace=True)

byage_df

plt.figure(figsize=(10, 5))
colors_ = ['#D3D3D3', '#72BCD4', '#D3D3D3']

ax = sns.barplot(
    data=byage_df,
    y='customer_count',
    x='age_group',
    order=['Youth', 'Adults', 'Seniors'],
    palette=colors_
)

for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                xytext=(0, 1),
                textcoords='offset points',
                ha='center', va='bottom')

plt.title('Number of Customer by Age', loc='center', fontsize=15)
plt.ylabel(None)
plt.xlabel(None)
plt.tick_params(axis='x', labelsize=12)

"""- From the plot above, the majority of customers are in the adult age group (adults).

### By state
"""

bystate_df = all_df.groupby(by='state').customer_id.nunique().reset_index()
bystate_df.rename(columns={
    'customer_id': 'customer_count'
}, inplace=True)

bystate_df

colors_ = ['#72BCD4', '#D3D3D3', '#D3D3D3', '#D3D3D3', '#D3D3D3', '#D3D3D3', '#D3D3D3', '#D3D3D3']
desc_bystate_df = bystate_df.sort_values(by='customer_count', ascending=False)

plt.figure(figsize=(10, 5))
sns.barplot(
    data=desc_bystate_df,
    x='customer_count',
    y='state',
    palette=colors_
)
plt.title('Number of Customer by States', loc='center', fontsize=15)
plt.ylabel(None)
plt.xlabel(None)
plt.tick_params(axis='y', labelsize=12)

for i, value in enumerate(desc_bystate_df['customer_count']):
    plt.text(
        x=value + 1,
        y=i,
        s=value,
        va='center',
    )

"""- Based on the visualization above, the majority of customers are from **South Australia** state.

## RFM Analysis

To answer the last three analysis questions, we can use RFM (Recency, Frequency, Monetary) analysis. RFM analysis is a customer segmentation method based on three parameters:
- **Recency**: Parameter used to determine when a customer last made a transaction.
- **Frequency**: Parameter used to identify how often a customer makes transactions.
- **Monetary**: Parameter used to identify how much revenue is generated from each customer.
"""

rfm_df = all_df.groupby(by='customer_id', as_index=False).agg({
    'order_date': 'max', # mengambil tanggal order terakhir
    'order_id': 'nunique', # menghitung jumlah order
    'total_price': 'sum' # menghitung jumlah revenue yang dihasilkan
})

rfm_df

rfm_df.columns = ['customer_id', 'max_order_timestamp', 'frequency', 'monetary']
rfm_df.head(2)

# menghitung kapan terakhir pelanggan melakukan transaksi (hari)
rfm_df['max_order_timestamp'] = rfm_df['max_order_timestamp'].dt.date
recent_date = orders_df['order_date'].dt.date.max()
rfm_df['recency'] = rfm_df['max_order_timestamp'].apply(
    lambda x: (recent_date - x).days
)

rfm_df.drop('max_order_timestamp', axis=1, inplace=True)
rfm_df.head()

asc_recency_rfm_df = rfm_df.sort_values(by="recency", ascending=True).head(5)
asc_recency_rfm_df

colors = ['#72BCD4']

fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 6))

# Plot pertama
asc_recency_rfm_df = rfm_df.sort_values(by='recency', ascending=True).head(5)
sns.barplot(
    y='recency',
    x='customer_id',
    data=asc_recency_rfm_df,
    palette=colors,
    order=asc_recency_rfm_df['customer_id'],
    ax=ax[0]
)
ax[0].set_ylabel(None)
ax[0].set_xlabel(None)
ax[0].set_title('By Recency (days)', loc='center', fontsize=18, pad=10)
ax[0].tick_params(axis ='x', labelsize=15)

for i, value in enumerate(asc_recency_rfm_df['recency']):
    ax[0].text(
        x=i,
        y=value + 0.02,
        s=value,
        ha='center',
    )

# Plot kedua
desc_frequency_rfm_df = rfm_df.sort_values(by='frequency', ascending=False).head(5)
sns.barplot(
    y='frequency',
    x='customer_id',
    data=desc_frequency_rfm_df,
    palette=colors,
    order=desc_frequency_rfm_df['customer_id'],
    ax=ax[1]
)
ax[1].set_ylabel(None)
ax[1].set_xlabel(None)
ax[1].set_title('By Frequency', loc='center', fontsize=18, pad=10)
ax[1].tick_params(axis='x', labelsize=15)

for i, value in enumerate(desc_frequency_rfm_df['frequency']):
    ax[1].text(
        x=i,
        y=value + 0.1,
        s=value,
        ha='center',
    )

# Plot ketiga
desc_monetary_rfm_df = rfm_df.sort_values(by='monetary', ascending=False).head(5)
sns.barplot(
    y='monetary',
    x='customer_id',
    data=desc_monetary_rfm_df,
    palette=colors,
    order=desc_monetary_rfm_df['customer_id'],
    ax=ax[2]
)
ax[2].set_ylabel(None)
ax[2].set_xlabel(None)
ax[2].set_title('By Monetary', loc='center', fontsize=18, pad=10)
ax[2].tick_params(axis='x', labelsize=15)

for i, value in enumerate(desc_monetary_rfm_df['monetary']):
    ax[2].text(
        x=i,
        y=value + 100,
        s=value,
        ha='center',
    )

plt.suptitle('Best Customer Based on RFM Parameters (customer_id)',
             fontsize=20, y=1);

"""- From the data visualization above, we can identify several customers who performed the best across all three parameters.

## Save Data Files
"""

all_df.to_csv('all_data.csv', index=False)

"""# CONCLUSION & RECOMMENDATION

**Conclusion**

- Based on the company's **sales** and **revenue** performance in recent months, **March** had the **highest** number of orders with **117 orders**. However, there was a significant **decrease** in the number of orders during **February, April, May,** and **October**. This also impacted the company's revenue. To address this decline, further analysis is needed regarding factors such as competition and marketing campaigns.

- In terms of product sales, **Denim** products were the **best-selling** with **527 units** sold, while **Mandarin Collar** products were the **least-selling** with only **236 units** sold.

- **Customer demographics** show that the majority of **customers did not disclose** their **gender** information. However, most customers are in the **adult age group** with **416 customers**. The highest number of customers come from **South Australia**.

- Finally, customers made transactions at least **1 day ago**, with some making transactions on the **same day**. On average, a customer makes **5 to 6 purchases** in recent months. The highest spending customer spent **AUD 7,632**.

**Recommendations**

Based on these findings, the company should focus on **increasing sales** during months with order declines. Additionally, the company can expand **marketing strategies** and **identify new opportunities** to attract more customers. It's also crucial to maintain and enhance the satisfaction of existing customers by providing excellent service and high-quality products.
"""